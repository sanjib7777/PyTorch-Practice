{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOol/Xt66jjqkuJkoJLMwxR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjib7777/PyTorch-Practice/blob/main/Next_Word_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wytJ4nnZbrKO",
        "outputId": "64fe9f0c-1be9-459b-f3f0-3144547b2d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "owK2oIyOb435"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can we contact you?\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "I am Sanjib Shah\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "u_MVf5a7cefm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPpd-7Szc9dP",
        "outputId": "29c232db-2615-4f55-ec03-dfde2fbcf7fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "EPM5nzY7dHJg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab ={'<UNK>':0}\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token]=len(vocab)\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_OlCtANdcSl",
        "outputId": "7e272f01-7f71-4caa-8e7d-a0758ab16b8d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract sentences from data\n",
        "input_sent = document.split('\\n')\n",
        "\n",
        "len(input_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uAYCGy_e1Uy",
        "outputId": "4dd80f27-1e47-48f8-c653-b2a6ca1d5287"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in input_sent:\n",
        "  print(word_tokenize(sentence.lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqNSXK_LfBtg",
        "outputId": "fb0f4293-a6e2-4e11-8dd1-a0809c612c1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['about', 'the', 'program']\n",
            "['what', 'is', 'the', 'course', 'fee', 'for', 'data', 'science', 'mentorship', 'program', '(', 'dsmp', '2023', ')']\n",
            "['the', 'course', 'follows', 'a', 'monthly', 'subscription', 'model', 'where', 'you', 'have', 'to', 'make', 'monthly', 'payments', 'of', 'rs', '799/month', '.']\n",
            "['what', 'is', 'the', 'total', 'duration', 'of', 'the', 'course', '?']\n",
            "['the', 'total', 'duration', 'of', 'the', 'course', 'is', '7', 'months', '.', 'so', 'the', 'total', 'course', 'fee', 'becomes', '799', '*', '7', '=', 'rs', '5600', '(', 'approx', '.', ')']\n",
            "['what', 'is', 'the', 'syllabus', 'of', 'the', 'mentorship', 'program', '?']\n",
            "['we', 'will', 'be', 'covering', 'the', 'following', 'modules', ':']\n",
            "['python', 'fundamentals']\n",
            "['python', 'libraries', 'for', 'data', 'science']\n",
            "['data', 'analysis']\n",
            "['sql', 'for', 'data', 'science']\n",
            "['maths', 'for', 'machine', 'learning']\n",
            "['ml', 'algorithms']\n",
            "['practical', 'ml']\n",
            "['mlops']\n",
            "['case', 'studies']\n",
            "['you', 'can', 'check', 'the', 'detailed', 'syllabus', 'here', '-', 'https', ':', '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390']\n",
            "['will', 'deep', 'learning', 'and', 'nlp', 'be', 'a', 'part', 'of', 'this', 'program', '?']\n",
            "['no', ',', 'nlp', 'and', 'deep', 'learning', 'both', 'are', 'not', 'a', 'part', 'of', 'this', 'program', '’', 's', 'curriculum', '.']\n",
            "['what', 'if', 'i', 'miss', 'a', 'live', 'session', '?', 'will', 'i', 'get', 'a', 'recording', 'of', 'the', 'session', '?']\n",
            "['yes', ',', 'absolutely', '.']\n",
            "['i', 'am', 'late', ',', 'can', 'i', 'join', 'the', 'program', 'in', 'the', 'middle', '?']\n",
            "['absolutely', ',', 'you', 'can', 'join', 'the', 'program', 'anytime', '.']\n",
            "['if', 'i', 'join/pay', 'in', 'the', 'middle', ',', 'will', 'i', 'be', 'able', 'to', 'see', 'all', 'the', 'past', 'lectures', '?']\n",
            "['yes', ',', 'once', 'you', 'make', 'the', 'payment', 'you', 'will', 'be', 'able', 'to', 'see', 'all', 'the', 'past', 'content', 'in', 'your', 'dashboard', '.']\n",
            "['where', 'do', 'i', 'have', 'to', 'submit', 'the', 'task', '?']\n",
            "['you', 'don', '’', 't', 'have', 'to', 'submit', 'the', 'task', '.', 'we', 'will', 'provide', 'you', 'with', 'the', 'solutions', ',', 'you', 'have', 'to', 'self', 'evaluate', 'the', 'task', 'yourself', '.']\n",
            "['will', 'we', 'do', 'case', 'studies', 'in', 'the', 'program', '?']\n",
            "['yes', '.']\n",
            "['where', 'can', 'we', 'contact', 'you', '?']\n",
            "['i', 'am', 'living', 'outside', 'india', 'and', 'i', 'am', 'not', 'able', 'to', 'make', 'the', 'payment', 'on', 'the', 'website', ',', 'what', 'should', 'i', 'do', '?']\n",
            "['you', 'have', 'to', 'contact', 'us', 'by', 'sending', 'a', 'mail', 'at', 'nitish.campusx', '@', 'gmail.com']\n",
            "['post', 'registration', 'queries']\n",
            "['till', 'when', 'can', 'i', 'view', 'the', 'paid', 'videos', 'on', 'the', 'website', '?']\n",
            "['this', 'one', 'is', 'tricky', ',', 'so', 'read', 'carefully', '.', 'you', 'can', 'watch', 'the', 'videos', 'till', 'your', 'subscription', 'is', 'valid', '.', 'suppose', 'you', 'have', 'purchased', 'subscription', 'on', '21st', 'jan', ',', 'you', 'will', 'be', 'able', 'to', 'watch', 'all', 'the', 'past', 'paid', 'sessions', 'in', 'the', 'period', 'of', '21st', 'jan', 'to', '20th', 'feb.', 'but', 'after', '21st', 'feb', 'you', 'will', 'have', 'to', 'purchase', 'the', 'subscription', 'again', '.']\n",
            "['but', 'once', 'the', 'course', 'is', 'over', 'and', 'you', 'have', 'paid', 'us', 'rs', '5600', '(', 'or', '7', 'installments', 'of', 'rs', '799', ')', 'you', 'will', 'be', 'able', 'to', 'watch', 'the', 'paid', 'sessions', 'till', 'aug', '2024', '.']\n",
            "['why', 'lifetime', 'validity', 'is', 'not', 'provided', '?']\n",
            "['because', 'of', 'the', 'low', 'course', 'fee', '.']\n",
            "['where', 'can', 'we', 'contact', 'you', '?']\n",
            "['i', 'am', 'living', 'outside', 'india', 'and', 'i', 'am', 'not', 'able', 'to', 'make', 'the', 'payment', 'on', 'the', 'website', ',', 'what', 'should', 'i', 'do', '?']\n",
            "['you', 'have', 'to', 'contact', 'us', 'by', 'sending', 'a', 'mail', 'at', 'nitish.campusx', '@', 'gmail.com']\n",
            "['post', 'registration', 'queries']\n",
            "['where', 'can', 'i', 'reach', 'out', 'in', 'case', 'of', 'a', 'doubt', 'after', 'the', 'session', '?']\n",
            "['you', 'will', 'have', 'to', 'fill', 'a', 'google', 'form', 'provided', 'in', 'your', 'dashboard', 'and', 'our', 'team', 'will', 'contact', 'you', 'for', 'a', '1', 'on', '1', 'doubt', 'clearance', 'session']\n",
            "['if', 'i', 'join', 'the', 'program', 'late', ',', 'can', 'i', 'still', 'ask', 'past', 'week', 'doubts', '?']\n",
            "['yes', ',', 'just', 'select', 'past', 'week', 'doubt', 'in', 'the', 'doubt', 'clearance', 'google', 'form', '.']\n",
            "['i', 'am', 'living', 'outside', 'india', 'and', 'i', 'am', 'not', 'able', 'to', 'make', 'the', 'payment', 'on', 'the', 'website', ',', 'what', 'should', 'i', 'do', '?']\n",
            "['you', 'have', 'to', 'contact', 'us', 'by', 'sending', 'a', 'mail', 'at', 'nitish.campusx', '@', 'gmai.com']\n",
            "['certificate', 'and', 'placement', 'assistance', 'related', 'queries']\n",
            "['what', 'is', 'the', 'criteria', 'to', 'get', 'the', 'certificate', '?']\n",
            "['there', 'are', '2', 'criterias', ':']\n",
            "['i', 'am', 'joining', 'late', '.', 'how', 'can', 'i', 'pay', 'payment', 'of', 'the', 'earlier', 'months', '?']\n",
            "['you', 'will', 'get', 'a', 'link', 'to', 'pay', 'fee', 'of', 'earlier', 'months', 'in', 'your', 'dashboard', 'once', 'you', 'pay', 'for', 'the', 'current', 'month', '.']\n",
            "['i', 'have', 'read', 'that', 'placement', 'assistance', 'is', 'a', 'part', 'of', 'this', 'program', '.', 'what', 'comes', 'under', 'placement', 'assistance', '?']\n",
            "['this', 'is', 'to', 'clarify', 'that', 'placement', 'assistance', 'does', 'not', 'mean', 'placement', 'guarantee', '.', 'so', 'we', 'dont', 'guarantee', 'you', 'any', 'jobs', 'or', 'for', 'that', 'matter', 'even', 'interview', 'calls', '.', 'so', 'if', 'you', 'are', 'planning', 'to', 'join', 'this', 'course', 'just', 'for', 'placements', ',', 'i', 'am', 'afraid', 'you', 'will', 'be', 'disappointed', '.', 'here', 'is', 'what', 'comes', 'under', 'placement', 'assistance']\n",
            "['portfolio', 'building', 'sessions']\n",
            "['soft', 'skill', 'sessions']\n",
            "['sessions', 'with', 'industry', 'mentors']\n",
            "['discussion', 'on', 'job', 'hunting', 'strategies']\n",
            "['i', 'am', 'sanjib', 'shah']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "  numerical_sent = []\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sent.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sent.append(vocab['<UNK>'])\n",
        "\n",
        "  return numerical_sent"
      ],
      "metadata": {
        "id": "1TwTn3T6frCP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices('i am sanjib shah', vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDqg9UVygDbE",
        "outputId": "2b21ee4e-e53f-4598-b813-566e4a9758d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[86, 0, 17, 0, 0, 83, 17, 0, 0, 86, 0, 0, 83, 0, 17, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_num_sent = []\n",
        "for sentence in input_sent:\n",
        "  input_num_sent.append(text_to_indices(word_tokenize(sentence.lower()), vocab))"
      ],
      "metadata": {
        "id": "aUcGULwIgKsl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_num_sent[59]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j6Mtq7ggrkB",
        "outputId": "e2391dce-8406-405b-bec6-ae6f50251fbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[86, 94, 235, 236]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_num_sent:\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "NJ94tV_pg53n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_WqorS5hfGJ",
        "outputId": "1485928f-fc82-4d7b-d185-df6d942265d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [4, 5], [4, 5, 2], [4, 5, 2, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ywzaYbiD_D",
        "outputId": "2d6e2c0a-41bf-4692-d63f-a23251ad2e5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)\n",
        ""
      ],
      "metadata": {
        "id": "GVOSQTk3i3Zo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[52])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Y04A2tjNg9",
        "outputId": "e91794f1-fa3f-45ee-a613-fc0d129f30d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "O68TKPtGjXii"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC3ACbbMjpFl",
        "outputId": "f42df2d5-a5bc-411d-e944-05b267b23d78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([689, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:,:-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "eu8vzCmVjrBJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhd781zFkMsq",
        "outputId": "34cebbca-7651-4c28-ecfd-2a7d6559bb1e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([689])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X =X\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.X[index], self.y[index]\n"
      ],
      "metadata": {
        "id": "C6kTAAzwkNdZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcOErboPkolO",
        "outputId": "78ef3771-1608-4813-b8cd-e5dee673e672"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "id": "yjiXOqNKk5ph"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input, output in dataloader:\n",
        "  print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOPoMTtqlEH6",
        "outputId": "5c115bc7-53bb-454a-fb01-5bbb90c5957d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([143, 160,   6,  30,  24,  65,   2,  36,   3, 221,  30, 193, 224, 116,\n",
            "          8,  33,  27, 174,   2,  26, 152,  99,  80,  73, 199, 101,  25,  86,\n",
            "          3, 165,  83,  30])\n",
            "tensor([  6, 187,  33, 132,   8,  48, 132,  65,  54, 129,  58,  41,  28,  78,\n",
            "        189,   5,  44, 203,   2, 101,   3,   2, 204, 236, 202, 182,  49,  85,\n",
            "         68,  89,  45,   6])\n",
            "tensor([ 17,  86,  23, 129,  46, 101,  22, 129,  27,  17,   2,   3, 111, 161,\n",
            "        211,  30, 130, 123,  25,  36, 135, 202,  33, 129,  94,  27, 190,  78,\n",
            "         94, 226,  81,  19])\n",
            "tensor([ 86,  73,  45, 113,  19,   2,  65,  31, 194, 185, 148, 121, 127,  33,\n",
            "         97, 102, 120,  46,   2, 104,  94,   5,  28,  30, 106, 130, 201, 106,\n",
            "         24,  18, 103,  94])\n",
            "tensor([ 82,  24, 193,  64, 143,  27,  14,   2,  60,  27, 205,  72,   5,  87,\n",
            "         23,  78,  25, 134,  98, 160,  23, 112,  24,  21,  80, 124, 122, 193,\n",
            "         28,  40,  30,  10])\n",
            "tensor([ 30,  88,  72, 229,   2,  89,   2,  24,  98,  78,  81, 139, 193,  65,\n",
            "        208, 183, 155,   5, 113,   2,  27, 128,  30,  31,   3, 126,  86, 195,\n",
            "         78, 136,   6,  30])\n",
            "tensor([127, 202,  96,  22, 220,  15,  24, 215,   5, 177,   3,  22,  65, 228,\n",
            "        122,  24, 111,  86, 111,  52, 100,  36, 104,   4,  96, 208,   2,  27,\n",
            "         94, 147,   2,   2])\n",
            "tensor([ 33,  36,  95,  23, 109,  78, 126,  86,  97,   7, 124,   0,  46,  76,\n",
            "          9,  57,  46,  22, 171,  38, 122,  53, 126, 127,  32, 198,  78,  33,\n",
            "        109,   8,  27,  27])\n",
            "tensor([ 17,  86,  22,  65, 107, 126,  28,  94,   6, 217, 139,  15, 187, 175,\n",
            "         24, 101,   2, 179, 186,   8,  91, 125,  97,  75, 117,  78,  12, 188,\n",
            "          2,  45,  45,  17])\n",
            "tensor([ 45,  76,  34, 172,  27,  78,   2,  84, 143,  39,   4,  27,  17, 177,\n",
            "         18,   2,  22, 165,  44,  75,  79, 183, 153,  24, 104,  97,   2,  24,\n",
            "         78, 234,  93, 122])\n",
            "tensor([  5, 128, 139, 213,   6,  20,   2,  43,   9, 184, 194,  11, 196,  30,\n",
            "         69, 167,  33,  24,  23, 194,  86, 213,  35,   3,   8, 203, 191,  23,\n",
            "         33,   5, 123,  15])\n",
            "tensor([130,  23,  58,  25,   9,   7, 192, 235,  30,  30,  81,  97,   2,   2,\n",
            "        156, 101,  76, 109,  96, 209,  95,  27, 133,   2, 145,  86, 122,   2,\n",
            "         11,  27, 126, 230])\n",
            "tensor([ 22,  24,   2,  50,  63,   8,   2, 193,   5,  97,  41, 194,  65,  22,\n",
            "          2,  81,  95, 122,  94, 162, 131, 150,  19,  73, 117, 207, 157, 207,\n",
            "        144,  86,   5, 112])\n",
            "tensor([ 22,  47,  73,  42,  22,  17,  35, 158, 133,  78, 138,  90, 214, 108,\n",
            "         33, 140,  44, 107,   3,  46, 131,  78,  78, 115,  16, 172,   2, 216,\n",
            "        181,  33,   2, 111])\n",
            "tensor([ 24,  33,  68,  71,  73,  13, 180,  24,  25,  80, 149, 166, 218,   6,\n",
            "         22,  94,  67,  65, 105,  86,   2, 159, 144,  89,   2,  86,  30,  63,\n",
            "         22, 114, 151,  86])\n",
            "tensor([ 97,  86,  30, 134,   2, 149,  74,  24,   2,  73,  94, 178, 210,  58,\n",
            "         22,  22,  96, 101,  75, 126,   2,  30,  22, 143,  81,  74,  33,  33,\n",
            "        136, 180, 177, 119])\n",
            "tensor([ 10,  97, 135, 232, 179,  17, 107, 113,  45, 209, 110, 111, 106, 103,\n",
            "         22,  86,  46,  24,  85, 207,  45,  50, 128,   8,   7,  22,  30,  86,\n",
            "        131,  29, 155, 110])\n",
            "tensor([ 90, 154,   2,   6,  73,   7, 163,  33,  50, 164,  45, 212, 107,  30,\n",
            "        219,  17, 222, 132, 146, 101,  46,  17, 194, 233, 153,  33, 189, 170,\n",
            "         10, 104, 149,  24])\n",
            "tensor([126,   2,  30,  78, 193,  64,   4, 125, 142,  86,   3, 110,  33,  24,\n",
            "         34, 102, 133,  12,  35,  30,  65,   2,  30,   2,   2,  94,  23,   4,\n",
            "        155,   5,  97,  23])\n",
            "tensor([134,  76, 153,   5,  90,  17, 123,  70,   2, 135, 206,  22,  33,  82,\n",
            "        103,  34, 107, 154, 147,  37,  86,  66,  23,  81, 141,  24,  33,  59,\n",
            "         17,  78,  33,  19])\n",
            "tensor([ 23, 223, 124, 177, 118,  24,  22,  45, 109,  43, 138,  33, 184,   8,\n",
            "         30,  45,   4, 127,  27,   3,  45, 140, 155,  44,  45,   2, 125, 200,\n",
            "         73,   2,  38,  24])\n",
            "tensor([ 17,   2,   2, 104,   2,  33,  44,  30,  12,  32,  23,  31, 176,  89,\n",
            "         17,  65,   5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first = True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_state, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "3Q_MLBJIlJO7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hZL2UE0MFUpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "5Iu3JRUIIFYk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rqKJkr0EIGDK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtG4m7tJUft",
        "outputId": "8048031e-977a-4b8f-f075-a0ae30cd0f4f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(237, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=237, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate )"
      ],
      "metadata": {
        "id": "hISEPe77JWHT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_x, batch_y in dataloader:\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch_x)\n",
        "    loss = criterion(output, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {total_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfkXMxAiJm1s",
        "outputId": "b0510347-83b5-4ec8-e846-5c3707f7aae7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 60.6659\n",
            "Epoch: 2, Loss: 53.3105\n",
            "Epoch: 3, Loss: 47.3283\n",
            "Epoch: 4, Loss: 40.9718\n",
            "Epoch: 5, Loss: 36.1032\n",
            "Epoch: 6, Loss: 31.6642\n",
            "Epoch: 7, Loss: 27.5206\n",
            "Epoch: 8, Loss: 24.1017\n",
            "Epoch: 9, Loss: 21.2371\n",
            "Epoch: 10, Loss: 18.7335\n",
            "Epoch: 11, Loss: 16.3479\n",
            "Epoch: 12, Loss: 14.3074\n",
            "Epoch: 13, Loss: 12.6557\n",
            "Epoch: 14, Loss: 11.4152\n",
            "Epoch: 15, Loss: 10.2970\n",
            "Epoch: 16, Loss: 9.2882\n",
            "Epoch: 17, Loss: 8.3926\n",
            "Epoch: 18, Loss: 7.7858\n",
            "Epoch: 19, Loss: 7.2679\n",
            "Epoch: 20, Loss: 6.6615\n",
            "Epoch: 21, Loss: 6.0988\n",
            "Epoch: 22, Loss: 5.7800\n",
            "Epoch: 23, Loss: 5.3537\n",
            "Epoch: 24, Loss: 5.0478\n",
            "Epoch: 25, Loss: 4.8183\n",
            "Epoch: 26, Loss: 4.5610\n",
            "Epoch: 27, Loss: 4.3793\n",
            "Epoch: 28, Loss: 4.3193\n",
            "Epoch: 29, Loss: 3.9960\n",
            "Epoch: 30, Loss: 3.8894\n",
            "Epoch: 31, Loss: 3.7575\n",
            "Epoch: 32, Loss: 3.7119\n",
            "Epoch: 33, Loss: 3.5373\n",
            "Epoch: 34, Loss: 3.4000\n",
            "Epoch: 35, Loss: 3.2974\n",
            "Epoch: 36, Loss: 3.2185\n",
            "Epoch: 37, Loss: 3.1886\n",
            "Epoch: 38, Loss: 3.0274\n",
            "Epoch: 39, Loss: 3.0834\n",
            "Epoch: 40, Loss: 2.9156\n",
            "Epoch: 41, Loss: 2.9460\n",
            "Epoch: 42, Loss: 2.7936\n",
            "Epoch: 43, Loss: 2.8621\n",
            "Epoch: 44, Loss: 2.7559\n",
            "Epoch: 45, Loss: 2.7965\n",
            "Epoch: 46, Loss: 2.6492\n",
            "Epoch: 47, Loss: 2.6505\n",
            "Epoch: 48, Loss: 2.7290\n",
            "Epoch: 49, Loss: 2.6126\n",
            "Epoch: 50, Loss: 2.4735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, vocab, text):\n",
        "\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "  # text to numerical indices\n",
        "  num_text = text_to_indices(tokenized_text, vocab)\n",
        "  # padding\n",
        "  padded_text =torch.tensor( [0]*(61-len(num_text))+num_text, dtype=torch.long).unsqueeze(0)\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "  # predicted index\n",
        "  value,index = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "x7dJknWKKTvG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"I am Sanjib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JX0bgSqxNECF",
        "outputId": "7168e1a2-6caf-4040-a07c-b78827a4ebfa"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am Sanjib shah'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHunHTwINHUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}